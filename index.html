<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DexDiff</title>
    <!-- Bulma CSS  -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">
    <!-- Font Awesome icons  -->
    <script src="https://kit.fontawesome.com/b165665cab.js" crossorigin="anonymous"></script>
    <style>
        .video-container, .image-container {
            display: flex;
            justify-content: center;
            gap: 20px; /* Adjust the gap between videos as needed */
        }

        .video-item, .image-item {
            text-align: center;
        }
    </style>
</head>

<body>
    <div class="container p-3 is-primary">
        <!-- Title section -->
        <div class="block is-center has-text-centered">
            <h1 class="title is-1 is-spaced">DexDiff: Towards Extrinsic Dexterity Manipulation of Ungraspable Objects in Unrestricted Environments</h1>
            <div style="font-size:25px;" class="columns is-mobile is-centered is-multiline"> Paper ID (604)
            </div>
            <div class="columns is-mobile is-centered is-multiline"> 
            </div>
        </div>

        <p>&nbsp;</p>

        <div>
            <p style="text-align:center;"><img src="./framework2.png" alt="intro"style="width:70%;" /> </p>
        </div>

        <p>&nbsp;</p>

        <!-- Abstract -->
        <div class="block box" class="has-text-centered">
            <div>
                <h2 class="title is-3 has-text-centered"> Abstract </h2>
                <p class="is-size-5 has-text-left">
                    Grasping large and flat objects (e.g. a book or a pan) is often regarded as an ungraspable task, which poses significant challenges due to the unreachable grasping poses. Previous works leverage Extrinsic Dexterity like walls or table edges to grasp such objects. However, they are limited to task-specific policies and lack task planning to find pre-grasp conditions. This makes it difficult to adapt to various environments and extrinsic dexterity constraints. Therefore, we present DexDiff, a robust robotic manipulation method for long-horizon planning with extrinsic dexterity. Specifically, we utilize a vision-language model (VLM) to perceive the environmental state and generate high-level task plans, followed by a goal-conditioned action diffusion (GCAD) model to predict the sequence of low-level actions. This model learns the low-level policy from offline data with the cumulative reward guided by high-level planning as the goal condition, which allows for improved prediction of robot actions. Experimental results demonstrate that our method not only effectively performs ungraspable tasks but also generalizes to previously unseen objects. It outperforms baselines by a 47% higher success rate in simulation and facilitates efficient deployment and manipulation in real-world scenarios.
                </p>
            </div>
        </div>


        <!-- Real World Demo -->
        <div class="block box" class="has-text-centered">
            <div class="has-text-centered">
                <h2 class="title is-3">Real-World Demo of Daily Life</h2>
                <p class="is-size-5">
                    The videos here are at 16x speed. (The grasping operation is at 1x speed)
                </p>
                <p>&nbsp;</p>
                <div class='video-container'>
                    <div class='video-item'>
                        <video width="600" autoplay muted controls>
                            <source src="./bookshelf2.mp4" type="video/mp4">
                        </video>
                        <h3 class="title is-4">(a) Bookshelf(seen)</h3>
                    </div>
                    <p>&nbsp;</p>
                    <div class='video-item'>
                        <video width="600" autoplay muted controls>
                            <source src="./3Dprinter2.mp4" type="video/mp4">
                        </video>
                        <h3 class="title is-4">(b) 3D Printer(unseen)</h3>
                    </div>
                </div>
                <p>&nbsp;</p>
                <p>&nbsp;</p>
                
                <div class='video-container'>
                    <div class='video-item'>
                        <video width="600" autoplay muted controls>
                            <source src="./drawer2.mp4" type="video/mp4">
                        </video>
                        <h3 class="title is-4">(c) Drawer(seen)</h3>
                    </div>
                    <p>&nbsp;</p>
                    <div class='video-item'>
                        <video width="600" autoplay muted controls>
                            <source src="./drawer_edge2.mp4" type="video/mp4">
                        </video>
                        <h3 class="title is-4">(d) Storage box(seen)</h3>
                    </div>
                </div>
                <p>&nbsp;</p>
                <p>&nbsp;</p>
                
                <h2 class="title is-3">Real-world Demo of Push to Wall</h2>
                <p class="is-size-5">
                    The videos here are at 16x speed. (The grasping operation is at 1x speed)
                </p>
                <p>&nbsp;</p>
                <div class='video-container'>
                    <div class='video-item'>
                        <video width="600" autoplay muted controls>
                            <source src="./push_to_wall(box)2.mp4" type="video/mp4">
                        </video>
                        <h3 class="title is-4">(a) Box(seen)</h3>
                    </div>
                    <p>&nbsp;</p>
                    <div class='video-item'>
                        <video width="600" autoplay muted controls>
                            <source src="./push_to_wall(blackbox)2.mp4" type="video/mp4">
                        </video>
                        <h3 class="title is-4">(b) Toolbox(seen)</h3>
                    </div>
                </div>
                <p>&nbsp;</p>
                <p>&nbsp;</p>

                <h2 class="title is-3">Real-world Demo of Push to Edge</h2>
                <p class="is-size-5">
                    The videos here are at 16x speed. (The grasping operation is at 1x speed)
                </p>
                <p>&nbsp;</p>
                <div class='video-container'>
                    <div class='video-item'>
                        <video width="600" autoplay muted controls>
                            <source src="./push_to_edge(box)2.mp4" type="video/mp4">
                        </video>
                        <h3 class="title is-4">(a) Box(seen)</h3>
                    </div>
                    <p>&nbsp;</p>
                    <div class='video-item'>
                        <video width="600" autoplay muted controls>
                            <source src="./push_to_edge(folder)2.mp4" type="video/mp4">
                        </video>
                        <h3 class="title is-4">(b) Folder(unseen)</h3>
                    </div>
                </div>
                <p>&nbsp;</p>
                <div class='video-container'>
                    <div class='video-item'>
                        <video width="600" autoplay muted controls>
                            <source src="./push_to_edge(pot)2.mp4" type="video/mp4">
                        </video>
                        <h3 class="title is-4">(c) Pan(seen)</h3>
                    </div>
                    <p>&nbsp;</p>
                    <div class='video-item'>
                        <video width="600" autoplay muted controls>
                            <source src="./push_to_edge(orangebox)2.mp4" type="video/mp4">
                        </video>
                        <h3 class="title is-4">(d) Medicine cabinet(unseen)</h3>
                    </div>
                </div>
                <p>&nbsp;</p>
                <p>&nbsp;</p>

                <h2 class="title is-3">Different Shapes of the Side of the Table</h2>
                <p class="is-size-5">
                    The videos here are at 16x speed. (The grasping operation is at 1x speed)
                </p>
                <p>&nbsp;</p>
                <div class='video-container'>
                    <div class='video-item'>
                        <video width="600" autoplay muted controls>
                            <source src="./push_to_irregular_edge(toolbox)2.mp4" type="video/mp4">
                        </video>
                        <h3 class="title is-4">(a) Irregular edge(unseen)</h3>
                    </div>
                    <p>&nbsp;</p>
                    <div class='video-item'>
                        <video width="600" autoplay muted controls>
                            <source src="./push_to_curved_edge(toolbox)2.mp4" type="video/mp4">
                        </video>
                        <h3 class="title is-4">(b) Curved edge(unseen)</h3>
                    </div>
                </div>
                <p>&nbsp;</p>
                <p>&nbsp;</p>

                <h2 class="title is-3">Visualization of Rollouts on the Simulation</h2>
                <p>&nbsp;</p>
                <div class="image-item">
                    <img src="./result_corl.png" alt="Image 1" width="1000">
                    <h3 class="title is-4">Depending on extrinsic dexterity structures, we get different high-level plans, and the proposed method enables precise robot manipulation on long-horizon tasks. (A) Broad, (B) Surround, (C) Basic, (D) Empty.</h3>
                </div>
                <p>&nbsp;</p>
                <p>&nbsp;</p>
            </div>
        </div>


    </div>

</body>

</html>
